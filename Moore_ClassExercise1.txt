Gregory Moore

Briefly describe any 5 concepts covered in the lecture 25. (5 points). Don't use more than three-four sentences per concept. 

A simple feed forward ANN has an input layer, hidden layer, and output layer. The input layer represents the features of the data, and the output layer is the target. The number of hidden layers and the number of nodes per hidden layer are decided by the model creator. 

Activation Functions are an important hyperparameter of the neural network. They define how the input is transformed as the output of a neuron/node. There are many to choose from and each come with their own considersations.  

The cost function in NN is MSE, it is also called the loss function (J). The goal is to minimize it by altering the weights and biases of the vectors. 

Backpropagation is a technique to minimize the cost function of the neural network. It works similarly to gradient descent, which we have learned before. We compute the gradients of each component and revise the weights and biases relative to the cost function. 

Neural network training can be monitored. The model loss for training and validation is plotted as a function of the number of epochs. 
